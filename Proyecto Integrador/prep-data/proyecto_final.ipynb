{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procesamiento de duplicados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el fin de optimizar el tiempo de procesamiento y tras un análisis del dataset se tomó la decisión de identificar y eliminar los duplicados. Esto implica tener en cuenta que, si bien se pretende conservar el registro más reciente de cada cédula, este registro puede tener información faltante que registros previos de la misma cédula pueden llegar a tener, es por eso que es necesario realizar una especie de \"merge\", dando como resultado una fila que conserva el object_id (identificador único usado en el sistema de información en la Gobernación) y el registro más reciente de cada columna para cada cédula."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detección de duplicados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como paso inicial se creó el método `encontrar_cedulas_duplicadas.py` para identificarlas y generar otro .csv con los duplicados; este .csv no será solo usado par debugging, sino también para tener trazabilidad y un registro de las cédulas que en pasos posteriores serán eliminadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Duplicate records have been saved to: listado_cedulas_duplicadas_20241103_175222.csv\n",
      "\n",
      "Duplicate cédulas found:\n",
      "extracted_cedula\n",
      "43480068      5\n",
      "43649085      4\n",
      "43650539      3\n",
      "70430805      3\n",
      "1036783633    3\n",
      "             ..\n",
      "1007112726    2\n",
      "15304332      2\n",
      "1038335462    2\n",
      "1038334362    2\n",
      "1007318412    2\n",
      "Name: count, Length: 826, dtype: int64\n",
      "\n",
      "Number of duplicate records: 1701\n",
      "\n",
      "Total records processed: 1701\n",
      "Cedulas duplicadas: <class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "from cedulas_duplicadas import find_duplicate_cedulas\n",
    "\n",
    "file_path = \"../pcd_0311.csv\"  # Replace with your file path\n",
    "duplicates, duplicate_records, output_file = find_duplicate_cedulas(file_path)\n",
    "    \n",
    "print(\"\\nDuplicate cédulas found:\")\n",
    "if len(duplicates) > 0:\n",
    "    print(duplicates)\n",
    "    print(f\"\\nNumber of duplicate records: {len(duplicate_records)}\")\n",
    "else:\n",
    "    print(\"No duplicate cédulas found\")\n",
    "    \n",
    "print(f\"\\nTotal records processed: {len(duplicate_records)}\")\n",
    "\n",
    "print(f\"Cedulas duplicadas: {type(duplicates)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Merge\" de datos actualizados "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'timestamp'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6312\\2593132310.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmerge_cedulas\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfind_and_merge_duplicates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Process the file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mfile_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"../pcd_0311.csv\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mduplicates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmerged_records\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_and_merge_duplicates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Display some results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Processed {len(duplicates)} duplicate cédulas\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Lenovo\\OneDrive\\Escritorio\\p_final_repo\\Proyecto Integrador\\prep-data\\merge_cedulas.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m     90\u001b[0m                     \u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdate_column\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m                     \u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m                     \u001b[0mna_position\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'last'\u001b[0m  \u001b[1;31m# Put records with invalid dates at the end\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m                 )\n\u001b[1;32m---> 94\u001b[1;33m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Warning: Error sorting dates for cédula {cedula}: {str(e)}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m                 \u001b[1;31m# If date sorting fails, keep original order\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Lenovo\\OneDrive\\Escritorio\\p_final_repo\\Proyecto Integrador\\prep-data\\merge_cedulas.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(df, duplicates)\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;34m'fields_filled_from_history'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     }\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;31m# Define the date column name - adjust this based on your actual column name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0mdate_column\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Fecha de la encuesta'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcedula\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mduplicates\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[1;31m# Get all records for this cédula\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[0m\n\u001b[0;32m   6754\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6755\u001b[0m             \u001b[1;31m# len(by) == 1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6756\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6757\u001b[0m             \u001b[0mby\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6758\u001b[1;33m             \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6759\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6760\u001b[0m             \u001b[1;31m# need to rewrap column in Series to apply key function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6761\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1774\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mother_axes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1775\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_level_reference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1776\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1777\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1778\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1779\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1780\u001b[0m         \u001b[1;31m# Check for duplicates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1781\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'timestamp'"
     ]
    }
   ],
   "source": [
    "from merge_cedulas import find_and_merge_duplicates\n",
    "\n",
    "# Process the file\n",
    "file_path = \"../pcd_0311.csv\"\n",
    "duplicates, merged_records, output_file = find_and_merge_duplicates(file_path)\n",
    "\n",
    "# Display some results\n",
    "print(f\"Processed {len(duplicates)} duplicate cédulas\")\n",
    "print(f\"Generated merged records file: {output_file}\")\n",
    "\n",
    "# Look at the date distribution in merged records\n",
    "print(\"\\nDate range of merged records:\")\n",
    "merged_records['fecha de la encuesta'] = pd.to_datetime(\n",
    "    merged_records['fecha de la encuesta'], \n",
    "    format='%m/%d/%Y %H:%M', \n",
    "    errors='coerce'\n",
    ")\n",
    "print(f\"Earliest date: {merged_records['fecha de la encuesta'].min()}\")\n",
    "print(f\"Latest date: {merged_records['fecha de la encuesta'].max()}\")\n",
    "\n",
    "# Check which columns still have missing values after merging\n",
    "null_counts = merged_records.isnull().sum()\n",
    "print(\"\\nColumns with null values after merging:\")\n",
    "print(null_counts[null_counts > 0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
